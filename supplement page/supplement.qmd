---
title: "Supplement"
subtitle: "For the article #Knowledge: Improving food-related knowledge via seeding implemented as a social media intervention"
date: "`r Sys.Date()`"
format: 
  html:
    code-fold: true
    code-copy: true
    code-tools: true
    df-print: kable
    toc: true
    toc-location: right
    fig-format: svg
    page-layout: full
    fig-height: 4
    fig-width:  9
    fig-align: center
    fig-cap-location: top
    embed-resources: true
  pdf:       
    toc: true
    toc-depth: 2
    fig-height: 4
    fig-width:  9
    fig-align: center
    df-print: kable
    fig-cap-location: top
    execute:
      echo: false
execute:
  warning: false
  messages: false
editor_options: 
  chunk_output_type: console
---

```{r setup}
#| code-summary: "Load packages"

# Packages
library(tidyverse)   # ggplot, dplyr, and friends
library(brms)        # Bayesian modeling through Stan
library(psych)       # For describe()
library(correlation) # For correlations with nicer output
library(patchwork)   # For combining plots
library(parameters)  # Nicer output of model results
library(tidybayes)   # Manipulate brms objects in a tidy way
library(scales)      # For formatting labels in ggplot
library(extrafont)   # to change ggplot font
library(kableExtra)  # for Latextables
library(papaja)      # better printing 
library(bayestestR)  # for describe_posterior() 
library(emmeans)     # for contrast()
library(BayesFactor) # for ttestBF() and anovaBF()
```

```{r ggplot}
#| code-summary: "Define ggplot theme"


# Plot colors
clrs <- c("#54AA8F","#00335B",
          "#22A884FF","#414487FF",
          "#496aa2","#e46c0a","#90b6d4")


# ggplot theme
theme_nice <- function(){
  theme_minimal(base_family = "Jost") +  
    theme(plot.title       = element_text(hjust = 0.5,size = 20),
          panel.grid.minor = element_blank(),
          text             = element_text(size  = 20),
          panel.border     = element_rect(colour = "black", linewidth = 0.5, fill = NA),
          axis.title.x     = element_text(margin = unit(c(3, 0, 0, 0), "mm")),
          axis.title.y     = element_text(margin = unit(c(3, 3, 0, 0), "mm"), angle = 90),
          legend.title     = element_text(face = "bold",size=16),
          strip.text       = element_text(face = "bold"),
          legend.position  = "bottom"
    )}
```

```{r helper-functions}
#| code-summary: "Helper Functions"


brms_plot <- function(mod,lim=c(0,5)){
  

  trace <-   mcmc_plot(temp, type = "trace", variable = "^b_", regex = TRUE) +
              theme_nice() +
              labs(title = "Traceplot")

  pp    <-  pp_check(temp,ndraws = 20) + 
              theme_nice() + xlim(lim[1],lim[2]) +
              labs(title = "Posterior Predictive Check", color = "") +
              scale_color_manual(values = clrs[c(2,7)], labels = c("Observed", "Predicted"))


  return(trace + pp)

  
}


```

```{r data}
#| code-summary: "Load data"
# load data
est <- read_csv2("../Data/df_analysis.csv")
```


# Demographics per Condition                                 

```{r demo}
# Make tidy df of needed variables
demo <- est %>% 
          select(ID,trained_criterion,est_criterion,age, gender, education_level) %>% 
          distinct() 



demo %>% 
  distinct() %>% 
  group_by(trained_criterion,est_criterion) %>% 
  summarise(m        = mean(age),
            sd       = sd(age),
            p_female = mean(gender=="female")*100,
            p_male   = mean(gender=="male")*100,
            p_male   = mean(gender=="male")*100,
            p_abi    = mean(education_level=="Abitur")*100,
            p_ba     = mean(education_level=="Bachelor")*100,
            p_ma     = mean(education_level=="Master")*100,
            p_other  = 100-(p_abi+p_ba+p_ma)) %>% 
  mutate_if(is.numeric,printnum,digits=1) %>% 
  mutate(age    = paste0(m," (",sd,")"),
         gender = paste0(p_female," / ",p_male," %"),
         edu    = paste0(p_abi ," / ",p_ba, " / ",p_ma, " / ",p_other," %")) %>% 
  select(trained_criterion,est_criterion,age:edu) %>% 
  kbl(col.names = c("Trained","Estimated","Age","Perc. Female/Male","Perc. GUEQ/BA/MA/Other"),digits = 2) %>% 
  kable_paper() %>% 
  column_spec(1, width="6em") %>% 
  column_spec(2, width="6em") 

```

*Note.* GUEQ = General University Entrance Qualification , BA = Bachelor's degree, MA = Master's degree


# Reactivity Effects in General Criterion Knowledge Question 

```{r bf_reactivity}
# Make tidy df of needed variables
temp <- est %>% 
          select(ID,trained_criterion,est_criterion,Kcal_knowledge,CO2_knowledge) %>% 
          distinct() %>% 
          mutate(trained_f   = factor(trained_criterion),
                 estimated_f = factor(est_criterion)) %>% 
          as.data.frame()  

bf_Kcal = anovaBF(Kcal_knowledge ~ trained_f * estimated_f, data=temp)
bf_CO2  = anovaBF(CO2_knowledge ~ trained_f * estimated_f, data=temp)
```


As stated in the main manuscript, participants reported knowing in general more about the calorie content of food items (*M* = 4.12, *SD* = 1.69) than their CO~2~ footprint (*M* = 2.08, *SD* = 1.32, Î´ = 2.02 \[1.67, 2.36\], BF~10~ \> 1000). However, we also found a small reactivity effect, where participants rated their knowledge of a criterion lower when they had to estimate this criterion beforehand. This effect was found when participants had to estimate calories in the main task (BF~10~ = `r printnum(extractBF(bf_Kcal)$bf[2])`) and also (but to smaller degree) when they had to estimate the carbon footprint (BF~10~ = `r printnum(extractBF(bf_CO2)$bf[2])`). See below for descriptive values and the corresponding figure of individual values.

```{r table_reactivity}
#| code-summary: "Table"

temp %>% 
  group_by(est_criterion) %>% 
  summarize(m_kcal  = mean(Kcal_knowledge),
            sd_kcal = sd(Kcal_knowledge),
            m_CO2   = mean(CO2_knowledge),
            sd_CO2  = sd(CO2_knowledge)) %>% 
  mutate("Knowledge: Kcal" = paste0(printnum(m_kcal)," (",printnum(sd_kcal),")"),
         "Knowledge: CO2" = paste0(printnum(m_CO2)," (",printnum(sd_CO2),")")) %>% 
  select("Estimated Criterion" = est_criterion, `Knowledge: Kcal`, `Knowledge: CO2`) %>% 
  kbl() %>% 
  kable_paper()

```

```{r plots_reactivity}
#| code-summary: "Plot"
#| fig-cap: "Figure S1. General knowledge ratings for C0~2~ footprint and calorie content of food items, depending on the estimated criterion in the main task."

temp %>% 
  pivot_longer(cols      = c(Kcal_knowledge,CO2_knowledge),
               names_to  = "criterion",
               values_to = "values") %>% 
  mutate(criterion   = ifelse(criterion   == "CO2_knowledge", "bold(Knowledge:~CO[2])","bold(Knowledge:~kcal)"),
         estimated_f = ifelse(estimated_f == "CO2","CO[2]","kcal")) %>% 
  ggplot(aes(x = estimated_f, y = values,  group = criterion)) +
    geom_jitter(width=0.1, height = 0.1)+ 
    stat_summary(fun.data = mean_se, geom = "errorbar",aes(color=criterion),width=0.1) +
    stat_summary(fun="mean",geom="line",lwd=0.8,aes(color=criterion)) +
    stat_summary(fun="mean",geom="point",size=4,aes(fill=criterion),shape=21) +
    scale_color_manual(values=c(clrs[4],clrs[3])) +
    scale_fill_manual(values=c(clrs[4],clrs[3])) +
    facet_wrap(. ~ criterion,labeller = label_parsed) +
    theme_nice() +
    scale_x_discrete(labels = parse_format()) +
    scale_y_continuous(breaks = 1:7) +
    labs(x = "Estimated Criterion",
         y = "Knowledge Rating") +
    theme(legend.position = "none") 
```

# Number of Likes Posts                                      

In the preregistration, we also predicted that a greater  seeding  effect when  participants  saw  more posts as indicated by the number of liked posts. However, as already stated in the main text, almost all participants liked every post, see the table below for the descriptive statistics and the Figure S2 for the distribution of liked posts per participant.

```{r table_posts}
#| code-summary: "Table"

est %>% 
  select(ID,"Account"=trained_criterion,n_posts_liked) %>% 
  distinct() %>% 
  group_by(Account) %>% 
  summarise(m   = mean(n_posts_liked),
            sd  = sd(n_posts_liked),
            min = min(n_posts_liked),
            max = max(n_posts_liked)) %>% 
  kbl(col.names = c("Account","M","SD","Min","Max"),digits = 2) %>% 
  kable_paper()

```


```{r plot_dist_posts}
#| code-summary: "Plot"
#| fig-cap: "Figure S2. Distribution of number of liked posts per participant."
#| fig-height: 5
#| fig-width:  8


est %>% 
  select(ID,trained_criterion,est_criterion,n_posts_liked) %>% 
  distinct() %>% 
  mutate(trained_criterion = ifelse(trained_criterion  == "CO2","CO[2]","kcal")) %>% 
  ggplot(aes(x = n_posts_liked,  fill = trained_criterion)) +
    geom_histogram(alpha=0.75,position = "identity",bins=25) +
    scale_fill_manual(values=c(clrs[4],clrs[3]),labels = parse_format()) +
    theme_nice() +
    labs(x    = "Liked X out of 30 possible posts (15 seeding + 15 trivia facts)",
         y    = "Frequency",
         fill = "Account:")

```


In addition, Figure S3 shows the scatter plots with the estimated regression line when using the number of liked posts as an predictor of OME or $\rho$ (all *p*s > 0.05)


```{r plot_posts}
#| code-summary: "Plot"
#| fig-cap: "Figure S3. Relationship of number of liked posts and OME/rank correlation (z-transformed) per trained and estimated criterion"
#| fig-height: 8
#| fig-width:  10

est %>% 
 select(ID,trained_criterion,est_criterion,n_posts_liked, OME_corr, rank_z) %>% 
 group_by(ID,trained_criterion,est_criterion) %>% 
 summarize(OME    = mean(OME_corr),
           rank_z = mean(rank_z),
           n_posts_liked = mean(n_posts_liked),
           .groups="drop") %>% 
  mutate(est_criterion = ifelse(est_criterion == "CO2",
                                "bold(Estimated:~CO[2])",
                                "bold(Estimated:~kcal)"),
         trained_criterion = ifelse(trained_criterion == "CO2",
                                    "CO[2]",
                                    "kcal")) %>% 
  rename(`Estimated Criterion` = est_criterion,
         `Trained Criterion`   = trained_criterion) %>% 
  pivot_longer(cols = c(OME, rank_z), names_to = "DV", values_to = "val") %>% 
  ggplot(aes(x = n_posts_liked, y = val,
             color = `Trained Criterion`, fill = `Trained Criterion`)) +
    geom_point(shape=21,color="black", alpha=.8, size = 2.5) +
    geom_smooth(method="lm",fullrange=TRUE,alpha=0.1) +
    scale_fill_manual(values=c(clrs[4],clrs[3]),labels = parse_format()) +
    scale_color_manual(values=c(clrs[4],clrs[3]),labels = parse_format()) +
    facet_grid(DV~`Estimated Criterion`,labeller = label_parsed) +
    labs(fill  = "Trained Criterion", 
         y     = "Dependet Variable",
         x     = "Number of liked posts") +
    theme_nice()
    



```



# Seeding Effects on Direct Learning                         


In the analysis of the effects of seeding on calories and CO~2~ reported in the main text, we used only the respective 45 transfer items. Here we report the results when using only the seeding items (see file [`analysis_Hypothesis1_seedingItems.R`](https://github.com/dizyd/Knowledge/blob/main/Scripts/analysis_Hypothesis1_seedingItems.R) for the underlying analysis code).

```{r load_models_seeding}
#| code-summary: "Load models & compute BF"

# Load model files
res_kcal_OME   <- brm(file="../Results/fit_H1a_Kcal_M1_seedingItemsOnly.rds")
res_kcal_OME0  <- brm(file="../Results/fit_H1a_Kcal_M0_seedingItemsOnly.rds")
res_CO2_OME    <- brm(file="../Results/fit_H1a_CO2_M1_seedingItemsOnly.rds")
res_CO2_OME0   <- brm(file="../Results/fit_H1a_CO2_M0_seedingItemsOnly.rds")
res_kcal_rank  <- brm(file="../Results/fit_H1b_kcal_M1_seedingItemsOnly.rds")
res_kcal_rank0 <- brm(file="../Results/fit_H1b_kcal_M0_seedingItemsOnly.rds")
res_CO2_rank   <- brm(file="../Results/fit_H1b_CO2_M1_seedingItemsOnly.rds")
res_CO2_rank0  <- brm(file="../Results/fit_H1b_CO2_M0_seedingItemsOnly.rds")

# Compute BFs
BF_kcal_OME  <- bayes_factor(res_kcal_OME, res_kcal_OME0, silent = T)
BF_CO2_OME   <- bayes_factor(res_CO2_OME, res_CO2_OME0, silent = T)
BF_kcal_rank <- bayes_factor(res_kcal_rank, res_kcal_rank0, silent = T)
BF_CO2_rank  <- bayes_factor(res_CO2_rank, res_CO2_rank0, silent = T)

# remove model objects to save some RAM
rm(list=ls(pattern="res_"))
```


**Metric Knowledge:** We found strong evidence for a large seeding effect on metric knowledge (reduction in OME) on the seeding items for CO~2~ (BF~10~ = `r printnum(BF_CO2_OME$bf)`, *b* = -0.49 [-0.19, -0.82]) and evidence for a smaller seeding effect for calories (BF~10~ = `r printnum(BF_kcal_OME$bf)`, *b* = -0.10 [-0.21, -0.01]). 

**Mapping Knowledge** In contrast, there was weak evidence for an effect of seeding on the mapping knowledge (increase in $\rho$) for participants who estimated calories (BF~10~ = `r printnum(BF_kcal_rank$bf)`, *b* = .08 [.01, .16]) but not CO~2~ (BF~10~ = `r printnum(BF_CO2_rank$bf)`).


# Detailed Modeling Results                                  

Here we provide for all models reported in the main manuscript more detailed modeling results, including a table with the mean, standard deviation, 95\%-HDI, effective sample size (ESS) and $\hat{R}$ for each estimated parameter (random and fixed), as well as figures showing the MCMC-traces for the main fixed effects parameters (intercept and effect parameter) and posterior predictive distributions of the complete model.

## Hypothesis 1a (OME)    


### CO~2~ M0

```{r h1aM0CO2}
#| fig-height: 5
#| fig-width:  14

# Load model 
temp <- brm(file="../Results/fit_H1a_CO2_M0.rds")

# Print Formular
temp$formula

# Make model parameter table
model_parameters(temp, centrality = "mean", dispersion = TRUE, 
                 ci_method = "hdi", effects = "all") %>% 
  kable(digits=2) %>% kable_paper()


# Make trace and pp-check plot
brms_plot(temp)
```

### CO~2~ M1

```{r h1aM1CO2}
#| fig-height: 5
#| fig-width:  14

# Load model 
temp <- brm(file="../Results/fit_H1a_CO2_M1.rds")

# Print Formular
temp$formula

# Make model parameter table
model_parameters(temp, centrality = "mean", dispersion = TRUE, 
                 ci_method = "hdi", effects = "all") %>% 
  kable(digits=2) %>% kable_paper()

# Make trace and pp-check plot
brms_plot(temp)  + plot_layout(widths = c(2, 1))
```

### kcal M0

```{r h1aM0kcal}
#| fig-height: 5
#| fig-width:  14

# Load model 
temp <- brm(file="../Results/fit_H1a_kcal_M0.rds")

# Print Formular
temp$formula

# Make model parameter table
model_parameters(temp, centrality = "mean", dispersion = TRUE, 
                 ci_method = "hdi", effects = "all") %>% 
  kable(digits=2) %>% kable_paper()


# Make trace and pp-check plot
brms_plot(temp)
```

### kcal M1

```{r h1aM1kcal}
#| fig-height: 5
#| fig-width:  14

# Load model 
temp <- brm(file="../Results/fit_H1a_kcal_M1.rds")

# Print Formular
temp$formula

# Make model parameter table
model_parameters(temp, centrality = "mean", dispersion = TRUE, 
                 ci_method = "hdi", effects = "all") %>% 
  kable(digits=2) %>% kable_paper()

# Make trace and pp-check plot
brms_plot(temp)  + plot_layout(widths = c(2, 1))
```


    
## Hypothesis 1b ($\rho$) 

### CO~2~ M0

```{r h1bM0CO2}
#| fig-height: 5
#| fig-width:  14

# Load model 
temp <- brm(file="../Results/fit_H1b_CO2_M0.rds")

# Print Formular
temp$formula

# Make model parameter table
model_parameters(temp, centrality = "mean", dispersion = TRUE, 
                 ci_method = "hdi", effects = "all") %>% 
  kable(digits=2) %>% kable_paper()


# Make trace and pp-check plot
brms_plot(temp,lim=c(-1,3))
```

### CO~2~ M1

```{r h1bM1CO2}
#| fig-height: 5
#| fig-width:  14

# Load model 
temp <- brm(file="../Results/fit_H1b_CO2_M1.rds")

# Print Formular
temp$formula

# Make model parameter table
model_parameters(temp, centrality = "mean", dispersion = TRUE, 
                 ci_method = "hdi", effects = "all") %>% 
  kable(digits=2) %>% kable_paper()

# Make trace and pp-check plot
brms_plot(temp,lim=c(-1,3))  + plot_layout(widths = c(2, 1))
```

### kcal M0

```{r h1bM0kcal}
#| fig-height: 5
#| fig-width:  14

# Load model 
temp <- brm(file="../Results/fit_H1b_kcal_M0.rds")

# Print Formular
temp$formula

# Make model parameter table
model_parameters(temp, centrality = "mean", dispersion = TRUE, 
                 ci_method = "hdi", effects = "all") %>% 
  kable(digits=2) %>% kable_paper()


# Make trace and pp-check plot
brms_plot(temp,lim=c(-1,3))
```

### kcal M1

```{r h1bM1kcal}
#| fig-height: 5
#| fig-width:  14

# Load model 
temp <- brm(file="../Results/fit_H1b_kcal_M1.rds")

# Print Formular
temp$formula

# Make model parameter table
model_parameters(temp, centrality = "mean", dispersion = TRUE, 
                 ci_method = "hdi", effects = "all") %>% 
  kable(digits=2) %>% kable_paper()

# Make trace and pp-check plot
brms_plot(temp,lim=c(-1,3))  + plot_layout(widths = c(2, 1))
```









    
    
    
    
    



## Hypothesis 2a (OME)    


### CO~2~ M0

```{r h2aM0CO2}
#| fig-height: 5
#| fig-width:  14

# Load model 
temp <- brm(file="../Results/fit_H2a_CO2_M0.rds")

# Print Formular
temp$formula

# Make model parameter table
model_parameters(temp, centrality = "mean", dispersion = TRUE, 
                 ci_method = "hdi", effects = "all") %>% 
  kable(digits=2) %>% kable_paper()


# Make trace and pp-check plot
brms_plot(temp)
```

### CO~2~ M1

```{r h2aM1CO2}
#| fig-height: 5
#| fig-width:  14

# Load model 
temp <- brm(file="../Results/fit_H2a_CO2_M1.rds")

# Print Formular
temp$formula

# Make model parameter table
model_parameters(temp, centrality = "mean", dispersion = TRUE, 
                 ci_method = "hdi", effects = "all") %>% 
  kable(digits=2) %>% kable_paper()

# Make trace and pp-check plot
brms_plot(temp)  + plot_layout(widths = c(2, 1))
```

### kcal M0

```{r h2aM0kcal}
#| fig-height: 5
#| fig-width:  14

# Load model 
temp <- brm(file="../Results/fit_H2a_kcal_M0.rds")

# Print Formular
temp$formula

# Make model parameter table
model_parameters(temp, centrality = "mean", dispersion = TRUE, 
                 ci_method = "hdi", effects = "all") %>% 
  kable(digits=2) %>% kable_paper()


# Make trace and pp-check plot
brms_plot(temp)
```

### kcal M1

```{r h2aM1kcal}
#| fig-height: 5
#| fig-width:  14

# Load model 
temp <- brm(file="../Results/fit_H2a_kcal_M1.rds")

# Print Formular
temp$formula

# Make model parameter table
model_parameters(temp, centrality = "mean", dispersion = TRUE, 
                 ci_method = "hdi", effects = "all") %>% 
  kable(digits=2) %>% kable_paper()

# Make trace and pp-check plot
brms_plot(temp)  + plot_layout(widths = c(2, 1))
```



    
## Hypothesis 2b ($\rho$) 

### CO~2~ M0

```{r h2bM0CO2}
#| fig-height: 5
#| fig-width:  14

# Load model 
temp <- brm(file="../Results/fit_H2b_CO2_M0.rds")

# Print Formular
temp$formula

# Make model parameter table
model_parameters(temp, centrality = "mean", dispersion = TRUE, 
                 ci_method = "hdi", effects = "all") %>% 
  kable(digits=2) %>% kable_paper()


# Make trace and pp-check plot
brms_plot(temp,lim=c(-1,3))
```

### CO~2~ M1

```{r h2bM1CO2}
#| fig-height: 5
#| fig-width:  14

# Load model 
temp <- brm(file="../Results/fit_H2b_CO2_M1.rds")

# Print Formular
temp$formula

# Make model parameter table
model_parameters(temp, centrality = "mean", dispersion = TRUE, 
                 ci_method = "hdi", effects = "all") %>% 
  kable(digits=2) %>% kable_paper()

# Make trace and pp-check plot
brms_plot(temp,lim=c(-1,3))  + plot_layout(widths = c(2, 1))
```

### kcal M0

```{r h2bM0kcal}
#| fig-height: 5
#| fig-width:  14

# Load model 
temp <- brm(file="../Results/fit_H2b_kcal_M0.rds")

# Print Formular
temp$formula

# Make model parameter table
model_parameters(temp, centrality = "mean", dispersion = TRUE, 
                 ci_method = "hdi", effects = "all") %>% 
  kable(digits=2) %>% kable_paper()


# Make trace and pp-check plot
brms_plot(temp,lim=c(-1,3))
```

### kcal M1

```{r h2bM1kcal}
#| fig-height: 5
#| fig-width:  14

# Load model 
temp <- brm(file="../Results/fit_H2b_kcal_M1.rds")

# Print Formular
temp$formula

# Make model parameter table
model_parameters(temp, centrality = "mean", dispersion = TRUE, 
                 ci_method = "hdi", effects = "all") %>% 
  kable(digits=2) %>% kable_paper()

# Make trace and pp-check plot
brms_plot(temp,lim=c(-1,3))  + plot_layout(widths = c(2, 1))
```









    
    
    
    
    




## Hypothesis 3a (OME)    

### M0


```{r h3aM0}
#| fig-height: 5
#| fig-width:  14

# Load model 
temp <- brm(file="../Results/fit_H3a_M0.rds")

# Print Formular
temp$formula

# Make model parameter table
model_parameters(temp, centrality = "mean", dispersion = TRUE, 
                 ci_method = "hdi", effects = "all") %>% 
  kable(digits=2) %>% kable_paper()


# Make trace and pp-check plot
brms_plot(temp) + plot_layout(widths = c(2, 1))
```



### M1


```{r h3aM1}
#| fig-height: 5
#| fig-width:  14

# Load model 
temp <- brm(file="../Results/fit_H3a_M1.rds")

# Print Formular
temp$formula

# Make model parameter table
model_parameters(temp, centrality = "mean", dispersion = TRUE, 
                 ci_method = "hdi", effects = "all") %>% 
  kable(digits=2) %>% kable_paper()


# Make trace and pp-check plot
brms_plot(temp) + plot_layout(widths = c(2, 1))
```


### M2


```{r h3aM2}
#| fig-height: 5
#| fig-width:  14

# Load model 
temp <- brm(file="../Results/fit_H3a_M2.rds")

# Print Formular
temp$formula

# Make model parameter table
model_parameters(temp, centrality = "mean", dispersion = TRUE, 
                 ci_method = "hdi", effects = "all") %>% 
  kable(digits=2) %>% kable_paper()


# Make trace and pp-check plot
brms_plot(temp) + plot_layout(widths = c(2, 1))
```













## Hypothesis 3b ($\rho$) 


### M0


```{r h3bM0}
#| fig-height: 5
#| fig-width:  14

# Load model 
temp <- brm(file="../Results/fit_H3b_M0.rds")

# Print Formular
temp$formula

# Make model parameter table
model_parameters(temp, centrality = "mean", dispersion = TRUE, 
                 ci_method = "hdi", effects = "all") %>% 
  kable(digits=2) %>% kable_paper()


# Make trace and pp-check plot
brms_plot(temp) + plot_layout(widths = c(2, 1))
```



### M1


```{r h3bM1}
#| fig-height: 5
#| fig-width:  14

# Load model 
temp <- brm(file="../Results/fit_H3b_M1.rds")

# Print Formular
temp$formula

# Make model parameter table
model_parameters(temp, centrality = "mean", dispersion = TRUE, 
                 ci_method = "hdi", effects = "all") %>% 
  kable(digits=2) %>% kable_paper()


# Make trace and pp-check plot
brms_plot(temp) + plot_layout(widths = c(2, 1))
```


### M2


```{r h3bM2}
#| fig-height: 5
#| fig-width:  14

# Load model 
temp <- brm(file="../Results/fit_H3b_M2.rds")

# Print Formular
temp$formula

# Make model parameter table
model_parameters(temp, centrality = "mean", dispersion = TRUE, 
                 ci_method = "hdi", effects = "all") %>% 
  kable(digits=2) %>% kable_paper()


# Make trace and pp-check plot
brms_plot(temp) + plot_layout(widths = c(2, 1))
```














                                    
                                    
                                    
# Calculation of Standardized Effect Sizes                   

As suggest by  Westfall et al. ([2014](https://doi.org/10.1037/xge0000014)) and others (e.g., Brysbaert & Stevens, [2018](https://doi.org/10.5334/joc.10)) we calculated standardized effect sizes in terms of Cohens $d$ by dividing the model based effect estimate by the total standard deviation (see file [`analysis_compute_standardized_effect_sizes.R`](https://github.com/dizyd/Knowledge/blob/main/Scripts/analysis_compute_standardized_effect_sizes.R) for the underlying analysis code). However, based on simulations and some checks, we decided against using the model based variance estimate to calculate the total standard deviation and instead directly computed it from the data. The reason for this was that there are some very small OME values as can be seen here when we plot the OME values on a normalized scale which reflects the data used by the log-normal model:


```{r logOME_dist_plot}
#| code-summary: "Plot"
#| fig-cap: "Figure S4. Distribution of normalized OMEs (i.e., log(OMEs))."
#| fig-height: 5
#| fig-width:  8

est %>% 
  filter(item_type == "transfer", est_criterion == "Kcal") %>% # filter data as in Analysis for Hypothesis 1a
   ggplot(aes(x = log(OME_corr))) +
      geom_histogram(alpha=0.75,position = "identity",bins=25) +
      scale_fill_manual(values=c(clrs[4],clrs[3]),labels = parse_format()) +
      theme_nice() +
      labs(x    = "log(OME)",
           y    = "Frequency")

```

These small values (e.g., OME < 0.02, log(OME) < -3.9) have a large biasing effect on the estimated standard deviation coefficients, especially for the random intercepts of items and the residual standard deviation. This increased estimates would then lead to a biased estimate of the effect size. The standard deviations on the normal scale are not influenced that much from these small values, thus we used the estimated total standard deviation from the corresponding OMEs (`sd(OME)`) and the estimated effects on the untransformed scale as reported in the paper to compute the estimated standardized effects. These effects are also more conservative (i.e., smaller) than computing the effects from aggregated data (i.e. from a *t*-test).







